{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of ObjectiveLearner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is ObjectieLearner\n",
    "\n",
    "**ObjectiveLearner** defines the python module `objlearner` that provides functionality to run machine learning (linear regression) and sensitivity analysis on the objective function versus parameter relationship using the thousands (to millions) of (sometimes expensive) objective function evaluations performed during model calibration with packages like [PyDREAM](https://github.com/LoLab-VU/PyDREAM), [simplePSO](https://github.com/LoLab-VU/ParticleSwarmOptimization), [Gleipnir](https://github.com/LoLab-VU/Gleipnir), and [GAlibrate](https://github.com/blakeaw/GAlibrate).\n",
    "\n",
    "ObjectiveLearner provides easy to use objective function decorators which allow users to save data from the objective function evaluations performed during model calibration, and thereby provides them a way to utilize what would typically be lost data (i.e., not saved by the calibrator) and learn even more about the objective function and its relationship to model parameters, as well as learn more about the underlying model and assumptions the objective function represents.\n",
    "\n",
    "ObjectiveLearner installs as the `objlearner` package which defines the three decorator classes:\n",
    "   * ObjectiveCounter - counts the number of objective function calls.\n",
    "   * ObjectiveSaver - saves the input-output pairs fo the objective function calls.\n",
    "   * ObjectiveLearner - provides machine learning (linear regression) and sensitivity analysis.\n",
    "\n",
    "In the following sections we'll cover each class and it's use. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Example Model\n",
    "\n",
    "For the purposes of this overview we will use the [GAlibrate](https://github.com/blakeaw/GAlibrate) package which defines a genetic algorithm optimizer: \n",
    "```\n",
    "pip install galibrate\n",
    "```\n",
    "or \n",
    "```\n",
    "conda install -c blakeaw galibrate\n",
    "```\n",
    "\n",
    "We will estimate the model parameters for a linear fit to three data points with uncertainty, an example adapted from the Nestle 'Getting started' section at: http://kylebarbary.com/nestle/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the imports we need from NumPy and GAlibrate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/blake/src/python/GAlibrate/galibrate/gao.py:10: RuntimeWarning: ------Running GAO with numba optimization.------\n",
      "  warnings.warn(\"------Running GAO with numba optimization.------\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from galibrate.sampled_parameter import SampledParameter\n",
    "from galibrate import GAO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is the data that we are going calibrate against:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the data points that are being fitted.\n",
    "data_x = np.array([1., 2., 3.])\n",
    "data_y = np.array([1.4, 1.7, 4.1])\n",
    "data_yerr = np.array([0.2, 0.15, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the objective function for this problem, a genetic algorithm fitness function which will be maximized by the GAO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness(chromosome):\n",
    "    y = chromosome[1] * data_x + chromosome[0]\n",
    "    chisq = np.sum(((data_y - y) / data_yerr)**2)\n",
    "    if np.isnan(chisq):\n",
    "        return -np.inf\n",
    "    return -chisq / 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ObjectiveCounter\n",
    "\n",
    "The ObjectiveCounter simply keeps count of the number of calls to the objective function. It's imported from `objlearner`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from objlearner import ObjectiveCounter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use it as a decorator for the objective function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ObjectiveCounter\n",
    "def fitness(chromosome):\n",
    "    y = chromosome[1] * data_x + chromosome[0]\n",
    "    chisq = np.sum(((data_y - y) / data_yerr)**2)\n",
    "    if np.isnan(chisq):\n",
    "        return -np.inf\n",
    "    return -chisq / 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we setup and run the calibration run as normal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling a total of 2 parameters\n",
      "Will use GA population size of 200\n",
      "[-0.33089809  1.24605161] -13.664009334856136\n"
     ]
    }
   ],
   "source": [
    "# Set up the list of sampled parameters\n",
    "parm_names = list(['m', 'b'])\n",
    "sampled_parameters = [SampledParameter(name=p, loc=-5.0, width=10.0) for p in parm_names]\n",
    "\n",
    "# Set the active point population size\n",
    "population_size = 200\n",
    "n_params = len(sampled_parameters)\n",
    "print(\"Sampling a total of {} parameters\".format(n_params))\n",
    "print(\"Will use GA population size of {}\".format(population_size))\n",
    "# Construct the GAO\n",
    "gao = GAO(sampled_parameters,\n",
    "         fitness,\n",
    "         population_size,\n",
    "         generations = 100,\n",
    "         mutation_rate = 0.1)\n",
    "# run it\n",
    "best, best_f = gao.run()\n",
    "print(best, best_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can access the information on the number of objective function evaluations with `count` member variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of fitness evaluations:  10300\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of fitness evaluations: \",fitness.count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ObjectiveSaver\n",
    "\n",
    "In addition to keeping count of the number of calls to the objective function, ObjectiveSaver also saves the input parameter vectors and the corresponding objective function evaluations. It's imported from `objlearner`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from objlearner import ObjectiveSaver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use it as a decorator for the objective function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ObjectiveSaver\n",
    "def fitness(chromosome):\n",
    "    y = chromosome[1] * data_x + chromosome[0]\n",
    "    chisq = np.sum(((data_y - y) / data_yerr)**2)\n",
    "    if np.isnan(chisq):\n",
    "        return -np.inf\n",
    "    return -chisq / 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we setup and run the calibration run as normal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling a total of 2 parameters\n",
      "Will use GA population size of 200\n",
      "[-0.12701344  1.2286512 ] -13.600164887776693\n"
     ]
    }
   ],
   "source": [
    "# Set up the list of sampled parameters\n",
    "parm_names = list(['m', 'b'])\n",
    "sampled_parameters = [SampledParameter(name=p, loc=-5.0, width=10.0) for p in parm_names]\n",
    "\n",
    "# Set the active point population size\n",
    "population_size = 200\n",
    "n_params = len(sampled_parameters)\n",
    "print(\"Sampling a total of {} parameters\".format(n_params))\n",
    "print(\"Will use GA population size of {}\".format(population_size))\n",
    "# Construct the GAO\n",
    "gao = GAO(sampled_parameters,\n",
    "         fitness,\n",
    "         population_size,\n",
    "         generations = 100,\n",
    "         mutation_rate = 0.1)\n",
    "# run it\n",
    "best, best_f = gao.run()\n",
    "print(best, best_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the principal information for the objective function evaluations is accessed with `objective_theta` member variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         objective         0         1\n",
      "0      -378.589375 -4.755865  4.362777\n",
      "1     -4586.718622 -1.515087 -2.798161\n",
      "2      -445.367602  1.198610  2.021765\n",
      "3      -354.921838 -1.450604  3.048453\n",
      "4      -567.588219  2.634260  1.523190\n",
      "...            ...       ...       ...\n",
      "10295 -2505.106490 -0.351074 -2.104487\n",
      "10296   -83.400251  1.073834  0.160292\n",
      "10297  -221.240213 -0.237476  0.272537\n",
      "10298  -186.489599  1.073834 -0.187327\n",
      "10299 -2188.824642 -0.674788 -1.737417\n",
      "\n",
      "[10300 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(fitness.objective_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which returns a pandas DataFrame.\n",
    "\n",
    "Additionally, the ObjectiveSaver defines the following member variable and functions:\n",
    "  * count - the number of objective function evaluations\n",
    "  * write_csv(prefix='filename_prefix') - write out the objective function evaluation data as a csv file\n",
    "  * write_npy(prefix='filename_prefix') - write out the objective function evaluation data as a NumPy npy file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ObjectiveLearner\n",
    "\n",
    "The ObjectiveLearner is the principal (and name) tool from the **ObjectiveLearner** package, and it provides functionanlity to analyze objective function evaluation data with machine learning (linear regression) and sensitivity analysis. It's imported from `objlearner`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from objlearner import ObjectiveLearner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use it as a decorator for the objective function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ObjectiveLearner\n",
    "def fitness(chromosome):\n",
    "    y = chromosome[1] * data_x + chromosome[0]\n",
    "    chisq = np.sum(((data_y - y) / data_yerr)**2)\n",
    "    if np.isnan(chisq):\n",
    "        return -np.inf\n",
    "    return -chisq / 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we setup and run the calibration run as normal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling a total of 2 parameters\n",
      "Will use GA population size of 200\n",
      "[-0.94778955  1.61824086] -14.820251155584078\n"
     ]
    }
   ],
   "source": [
    "# Set up the list of sampled parameters\n",
    "parm_names = list(['m', 'b'])\n",
    "sampled_parameters = [SampledParameter(name=p, loc=-5.0, width=10.0) for p in parm_names]\n",
    "\n",
    "# Set the active point population size\n",
    "population_size = 200\n",
    "n_params = len(sampled_parameters)\n",
    "print(\"Sampling a total of {} parameters\".format(n_params))\n",
    "print(\"Will use GA population size of {}\".format(population_size))\n",
    "# Construct the GAO\n",
    "gao = GAO(sampled_parameters,\n",
    "         fitness,\n",
    "         population_size,\n",
    "         generations = 100,\n",
    "         mutation_rate = 0.1)\n",
    "# run it\n",
    "best, best_f = gao.run()\n",
    "print(best, best_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machine Learning (Linear Regression)\n",
    "\n",
    "The CostLearner decorator provides several functions to compute the coefficients and explained variance score between the objective function and input parameter vectors using linear regression methods (form [scikit-learn](https://scikit-learn.org/stable/index.html)):\n",
    "\n",
    "  * least_squares() - Least squares linear regression of the objective function against the parameters.\n",
    "  * ridge() - Ridge regression of the objective function against the parameters.\n",
    "  * lasso() - Lasso regression of the objective function against the parameters.\n",
    "  * linear_svr() - Linear Support Vector Regression (SVR) of the objective function against the parameters.\n",
    "  \n",
    "For example:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Least-squares linear regression coefficients and explained variance score:\n",
      "[232.58851622 478.82551034] 0.3588026227732696\n"
     ]
    }
   ],
   "source": [
    "coefs, ev_score = fitness.least_squares()\n",
    "print(\"Least-squares linear regression coefficients and explained variance score:\")\n",
    "print(coefs, ev_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sensitivity Analysis\n",
    "\n",
    "The CostLearner decorator also provides several functions to compute sensitivity metrics between the objective function and input parameter vectors using sensitivity analyses (from [SALib](https://salib.readthedocs.io/en/latest/index.html)):\n",
    "\n",
    "  * sobol() - Sobol sensitivity of the objective function.\n",
    "  * morris() - Morris Method sensitivity of the objective function.\n",
    "  * delta() - Delta Moment-Independent Measure sensitivity of the objective function.\n",
    "  * fast() - FAST sensitivity analysis of the objective function.\n",
    "  * rbd_fast() - RBD-FAST sensitivity analysis of the objective function.\n",
    "  \n",
    "For example:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'S1': array([0.06167879, 0.60798909]), 'S1_conf': array([0.04306523, 0.0665324 ]), 'ST': array([0.39456359, 0.94167418]), 'ST_conf': array([0.03766878, 0.0691636 ]), 'S2': array([[       nan, 0.34303938],\n",
      "       [       nan,        nan]]), 'S2_conf': array([[       nan, 0.09877772],\n",
      "       [       nan,        nan]])}\n"
     ]
    }
   ],
   "source": [
    "Si = fitness.sobol()\n",
    "print(Si)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
